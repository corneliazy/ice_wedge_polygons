# -*- coding: utf-8 -*-
"""mask_rcnn_big.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dZXOp04PL7oT70T4EzNkEjM2SULhNKZF

### Clone repository
Repository based on https://github.com/matterport/Mask_RCNN with minor changes to solve version conflicts and toadapt tocustomdataset.
"""

!git clone https://github.com/Wagner-L/Mask_RCNN

"""### Install right version oflibraries
keras and tensorflow is required in outdated versions.
"""

!pip install tensorflow==1.13.1
!pip install keras==2.0.9
!pip install h5py==2.10.0

"""Pre-trained weights from the original implementation can be downloaded and used as starting point for on-top training."""

import os
!git checkout 555126ee899a144ceff09e90b5b2cf46c321200c
!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5

"""### Import of libraries"""

import os
import sys
import random
import math
import numpy as np
import skimage.io
import matplotlib
import matplotlib.pyplot as plt

# Root directory of the project
ROOT_DIR = os.path.abspath("../Mask_RCNN")
ROOT_DIR

# Import Mask RCNN
sys.path.append("/content/Mask_RCNN") 
sys.path.append("/content/sample_data/Mask_RCNN") # To find local version of the library
from mrcnn import utils
import mrcnn.model as modellib
from mrcnn import visualize
# Import COCO config
sys.path.append(os.path.join(ROOT_DIR, "/content/Mask_RCNN/samples/coco/"))  # To find local version
import coco

sys.path.append(ROOT_DIR)  # To find local version of the library
from mrcnn.config import Config
from mrcnn import utils
import mrcnn.model as modellib
from mrcnn import visualize
from mrcnn.model import log

"""### Model and training configuration """

class CustomConfig(Config):
    """Configuration for training on the dataset.
    Derives from the base Config class and overrides some values.
    """
    # Give the configuration a recognizable name
    NAME = "object"
    # We use a GPU with 12GB memory, which can fit two images.
    # Adjust down if you use a smaller GPU.
    IMAGES_PER_GPU = 1 
    # Number of classes (including background)
    NUM_CLASSES = 1 + 1  
    # Background + polygons    # Number of training steps per epoch
    STEPS_PER_EPOCH = 30   
    # Skip detections with < 90% confidence
    DETECTION_MIN_CONFIDENCE = 0.9
    #LEARNING_RATE = 0.01

"""### Setting up custom dataset class"""

class CustomDataset(utils.Dataset):
  def load_custom(self, dataset_dir, subset):
    self.add_class("object", 1, "pol")
    #self.add_class("object", 2, "Man")
    assert subset in ["train", "val"]
    dataset_dir = os.path.join(dataset_dir, subset)

    annotations1 = json.load(open(os.path.join(dataset_dir, "via_project.json")))
    annotations = list(annotations1.values())  # don't need the dict keys
    annotations = [a for a in annotations if a['regions']]
    print(annotations)
    # Add images
    for a in annotations:
      # print(a)
            # Get the x, y coordinaets of points of the polygons that make up
            # the outline of each object instance. There are stores in the
            # shape_attributes (see json format above)
      polygons = [r['shape_attributes'] for r in a['regions']] 
      objects = [s['region_attributes']['name'] for s in a['regions']]
      print("objects:",objects)
      name_dict = {"pol": 1} #,"xyz": 3}
      # key = tuple(name_dict)
      num_ids = [name_dict[a] for a in objects]
     
            # num_ids = [int(n['Event']) for n in objects]
            # load_mask() needs the image size to convert polygons to masks.
            # Unfortunately, VIA doesn't include it in JSON, so we must read
            # the image. This is only managable since the dataset is tiny.
      print("numids",num_ids)
      image_path = os.path.join(dataset_dir, a['filename'])
      image = skimage.io.imread(image_path)
      height, width = image.shape[:2]    

      self.add_image(
                "object",  ## for a single class just add the name here
                image_id=a['filename'],  # use file name as a unique image id
                path=image_path,
                width=width, height=height,
                polygons=polygons,
                num_ids=num_ids
                )

"""### Load training and validation data"""

import json
dataset_val = CustomDataset()
dataset_val.load_custom( "/content/drive/MyDrive/Colab Notebooks/dataset/", "val")
dataset_val.prepare()

dataset_train = CustomDataset()
dataset_train.load_custom( "/content/drive/MyDrive/Colab Notebooks/dataset_big_tiles/", "train")
dataset_train.prepare()

"""### Preparation of model"""

DEFAULT_LOGS_DIR =  os.path.join(ROOT_DIR, "logs")
COCO_WEIGHTS_PATH = "/content/drive/MyDrive/Colab Notebooks/mask_rcnn_coco.h5"

config = CustomConfig()
model = modellib.MaskRCNN(mode="training", config=config, model_dir=DEFAULT_LOGS_DIR)

weights_path = COCO_WEIGHTS_PATH
        # Download weights file
if not os.path.exists(weights_path):
  utils.download_trained_weights(weights_path)

# load weights from original repositoy (previously downloaded)
#model.load_weights(weights_path, by_name=True, exclude=[
#            "mrcnn_class_logits", "mrcnn_bbox_fc",
#            "mrcnn_bbox", "mrcnn_mask"])

# load existing weight from previous training
model.load_weights("/content/my_model_big_20210929_big.h5", by_name=True, exclude=[
            "mrcnn_class_logits", "mrcnn_bbox_fc",
            "mrcnn_bbox", "mrcnn_mask"])

"""### Training"""

model.train(dataset_train, dataset_val,
                learning_rate=config.LEARNING_RATE,
                epochs=5,
                layers='heads')

model.keras_model.summary()

# save model
model.keras_model.save_weights("my_model_big_20210929_big_tiles.h5")

"""### Testing"""

DEVICE = "/gpu:0"  # /cpu:0 or /gpu:0

TEST_MODE = "inference"

def get_ax(rows=1, cols=1, size=16):  
  _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))  
  return ax

# Prepare model for prediction
import tensorflow
with tensorflow.device(DEVICE):
  pred_model = modellib.MaskRCNN(mode="inference", model_dir = DEFAULT_LOGS_DIR, config=config)

# Load previously trained weights 
pred_model.load_weights("/content/my_model_big_20210929_big.h5", by_name=True)

#run detection and display result
#image_id = random.choice(dataset_val.image_ids)
image_id = 16
print(image_id)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
  modellib.load_image_gt(dataset_val, config, image_id, use_mini_mask=False)
info = dataset_val.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id,dataset_val.image_reference(image_id)))
results = pred_model.detect([image], verbose=1)
x = get_ax(1)
r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset_val.class_names, r['scores'], ax=x, title="Predictions")

"""prediction with bigger image

"""

#RUN DETECTION

image, image_meta, gt_class_id, gt_bbox, gt_mask =\
  modellib.load_image_gt(dataset_val, config, image_id, use_mini_mask=False)
info = dataset_val.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id,dataset_val.image_reference(image_id)))

image =  skimage.io.imread("/content/drive/MyDrive/Colab Notebooks/dataset/samoylov_VIS_training_extent.jpeg")
result = pred_model.detect([image], verbose=1)

r = result[0]
class_names = ['BG', 'pol']
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            class_names, r['scores'])